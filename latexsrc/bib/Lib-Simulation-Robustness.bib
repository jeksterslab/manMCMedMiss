% Encoding: US-ASCII

@Article{
	Lib-Simulation-Robustness-Cochran-1952
	,
	author       = {
		Cochran, William G.
	},
	date         = {
		1952-09
	},
	journaltitle = {
		The Annals of Mathematical Statistics
	},
	title        = {
		The $\chi^{2}$ test of goodness of fit
	},
	doi          = {
		10.1214/aoms/1177729380
	},
	number       = {
		3
	},
	pages        = {
		315--345
	},
	volume       = {
		23
	},
	publisher    = {
		Institute of Mathematical Statistics
	},
	file = {
		references/10.1214%2Faoms%2F1177729380.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Simulation-Robustness
	},
	abstract     = {
		This paper contains an expository discussion of the chi square test of goodness of fit, 
		intended for the student and user of statistical theory rather than for the expert.
		Part I describes the historical development of the distribution theory on which the test rests.
		Research bearing on the practical application of the test--in particular on the minimum expected number per class and the construction of classes--is discussed in Part II.
		Some varied opinions about the extent to which the test actually is useful to the scientist are presented in Part III. 
		Part IV outlines a number of tests that have been proposed as substitutes for the chi square test (the $\omega^2$ test, 
		the smooth test, 
		the likelihood ratio test) and Part V a number of supplementary tests (the run test, tests based on low moments, 
		subdivision of chi square into components).
	},
}

@Article{
	Lib-Simulation-Robustness-Bradley-1978
	,
	author       = {
		Bradley, James V.
	},
	date         = {
		1978-11
	},
	journaltitle = {
		British Journal of Mathematical and Statistical Psychology
	},
	title        = {
		Robustness?
	},
	doi          = {
		10.1111/j.2044-8317.1978.tb00581.x
	},
	number       = {
		2
	},
	pages        = {
		144--152
	},
	volume       = {
		31
	},
	publisher    = {
		Wiley
	},
	file = {
		references/10.1111%2Fj.2044-8317.1978.tb00581.x.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Simulation-Robustness
	},
	abstract     = {
		The actual behaviour of the probability of a Type I error under assumption violation is quite complex,
		depending upon a wide variety of interacting factors.
		Yet allegations of robustness tend to ignore its highly particularistic nature and neglect to mention important qualifying conditions. 
		The result is often a vast overgeneralization which nevertheless is difficult to refute since a standard quantitative definition of what constitutes robustness does not exist. 
		Yet under any halfway reasonable quantitative definition,
		many of the most prevalent claims of robustness would be demonstrably false. 
		Therefore robustness is a highly questionable concept.
	},
}

@Article{
	Lib-Simulation-Robustness-Serlin-1985
	,
	author       = {
		Serlin, Ronald C. 
		and 
		Lapsley, Daniel K.
	},
	date         = {
		1985
	},
	journaltitle = {
		American Psychologist
	},
	title        = {
		Rationality in psychological research: The good-enough principle
	},
	doi          = {
		10.1037/0003-066x.40.1.73
	},
	number       = {
		1
	},
	pages        = {
		73--83
	},
	volume       = {
		40
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F0003-066X.40.1.73.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Simulation-Robustness
	},
	abstract     = {
		Reexamines methodological and procedural issues raised by P. Meehl (1967; see also PA, Vol 62:5042) that question the rationality of psychological inquiry. 
		Issues concern the asymmetry in theory testing between psychology and physics and the slow progress observed in psychological research. 
		A good-enough principle is proposed to resolve Meehl's methodological paradox, 
		and a more powerful reconstruction of science developed by I. Lakatos (1978) is suggested to account for the actual practice of psychological researchers.
	},
}

@Article{
	Lib-Simulation-Robustness-Robey-1992
	,
	author       = {
		Robey, Randall R. 
		and 
		Barcikowski, Robert S.
	},
	date         = {
		1992-11
	},
	journaltitle = {
		British Journal of Mathematical and Statistical Psychology
	},
	title        = {
		Type {I} error and the number of iterations in {Monte Carlo} studies of robustness
	},
	doi          = {
		10.1111/j.2044-8317.1992.tb00993.x
	},
	number       = {
		2
	},
	pages        = {
		283--288
	},
	volume       = {
		45
	},
	publisher    = {
		Wiley
	},
	file = {
		references/10.1111%2Fj.2044-8317.1992.tb00993.x.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Simulation-Robustness
	},
	abstract     = {
		A recent survey of simulation studies concluded that an overwhelming majority of papers do not report a rationale for the decision regarding the number of Monte Carlo iterations. 
		A surprisingly large number of reports do not contain a justifiable definition of robustness and many studies are conducted with an insufficient number of iterations to achieve satisfactory statistical conclusion validity. 
		The implication is that we do not follow our own advice regarding the management of Type I and Type II errors when conducting Monte Carlo experiments. 
		This paper reports a straightforward application of a well-known procedure for the purpose of objectively determining the exact number of iterations necessary to confidently detect departures from robustness in Monte Carlo results. 
		A table of the number of iterations necessary to detect departures from a series of nominal Type I error rates is included.
	},
}

@Article{
	Lib-Simulation-Robustness-Serlin-2000
	,
	author       = {
		Serlin, Ronald C.
	},
	date         = {
		2000
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		Testing for robustness in {Monte Carlo} studies
	},
	doi          = {
		10.1037/1082-989x.5.2.230
	},
	number       = {
		2
	},
	pages        = {
		230--240
	},
	volume       = {
		5
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F1082-989x.5.2.230.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Simulation-Robustness
	},
	abstract     = {
		Monte Carlo studies provide the information needed to help researchers select appropriate analytical procedures under design conditions in which the underlying assumptions of the procedures are not met.
		In Monte Carlo studies, 
		the 2 errors that one could commit involve (a) concluding that a statistical procedure is robust when it is not or (b) concluding that it is not robust when it is. 
		In previous attempts to apply standard statistical design principles to Monte Carlo studies, 
		the less severe of these errors has been wrongly designated the Type I error. 
		In this article, 
		a method is presented for controlling the appropriate Type I error rate; 
		the determination of the number of iterations required in a Monte Carlo study to achieve desired power is described; 
		and a confidence interval for a test's true Type I error rate is derived. 
		A robustness criterion is also proposed that is a compromise between W. G. Cochran's (1952) and J. V. Bradley's (1978) criteria.
	},
}

@Comment{jabref-meta: databaseType:biblatex;}