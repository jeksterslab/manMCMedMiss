% Encoding: US-ASCII

@Article{
	Lib-Mediation-Joint-Significance-Test-MacKinnon-2002
	,
	author       = {
		MacKinnon, David P. 
		and 
		Lockwood, Chondra M. 
		and 
		Hoffman, Jeanne M. 
		and 
		West, Stephen G. 
		and 
		Sheets, Virgil
	},
	date         = {
		2002
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		A comparison of methods to test mediation and other intervening variable effects
	},
	doi          = {
		10.1037/1082-989x.7.1.83
	},
	number       = {
		1
	},
	pages        = {
		83--104
	},
	volume       = {
		7
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F1082-989x.7.1.83.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Joint-Significance-Test
	},
	abstract     = {
		A Monte Carlo study compared 14 methods to test the statistical significance of the intervening variable effect. 
		An intervening variable (mediator) transmits the effect of an independent variable to a dependent variable. 
		The commonly used R. M. Baron and D. A. Kenny (1986) approach has low statistical power. 
		Two methods based on the distribution of the product and 2 difference-in-coefficients methods have the most accurate Type I error rates and greatest statistical power except in 1 important case in which Type I error rates are too high. 
		The best balance of Type I error and statistical power across all cases is the test of the joint significance of the two effects comprising the intervening variable effect.
	},
}

@Article{
	Lib-Mediation-Joint-Significance-Test-Yzerbyt-2018
	,
	author       = {
		Yzerbyt, Vincent
		and
		Muller, Dominique
		and
		Batailler, C{\'{e}}dric
		and
		Judd, Charles M.
	},
	date         = {
		2018-12
	},
	journaltitle = {
		Journal of Personality and Social Psychology
	},
	title        = {
		New recommendations for testing indirect effects in mediational models: The need to report and test component paths
	},
	doi          = {
		10.1037/pspa0000132
	},
	number       = {
		6
	},
	pages        = {
		929--943
	},
	volume       = {
		115
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2Fpspa0000132.pdf
	},
	library = {},
	keywords = {
		indirect effects, 
		mediation, 
		joint-significance, 
		bootstrap
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Joint-Significance-Test
	},
	abstract     = {
		In light of current concerns with replicability and reporting false-positive effects in psychology,
		we examine Type I errors and power associated with 2 distinct approaches for the assessment of mediation,
		namely the component approach (testing individual parameter estimates in the model) and the index approach (testing a single mediational index).
		We conduct simulations that examine both approaches and show that the most commonly used tests under the index approach risk inflated Type I errors compared with the joint-significance test inspired by the component approach.
		We argue that the tendency to report only a single mediational index is worrisome for this reason and also because it is often accompanied by a failure to critically examine the individual causal paths underlying the mediational model.
		We recommend testing individual components of the indirect effect to argue for the presence of an indirect effect and then using other recommended procedures to calculate the size of that effect. 
		Beyond simple mediation,
		we show that our conclusions also apply in cases of within-participant mediation and moderated mediation.
		We also provide a new R-package that allows for an easy implementation of our recommendations.
	},
}

@Comment{jabref-meta: databaseType:biblatex;}