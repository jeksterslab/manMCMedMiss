% Encoding: US-ASCII

@Article{
	Lib-Missing-Data-Rubin-1976
	,
	author       = {
		Rubin, Donald B.
	},
	date         = {
		1976
	},
	journaltitle = {
		Biometrika
	},
	title        = {
		Inference and missing data
	},
	doi          = {
		10.1093/biomet/63.3.581
	},
	number       = {
		3
	},
	pages        = {
		581--592
	},
	volume       = {
		63
	},
	publisher    = {Oxford University Press ({OUP})},
	file = {
		references/10.1093%2Fbiomet%2F63.3.581.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		When making sampling distribution inferences about the parameter of the data, 
		$\theta$, 
		it is appropriate to ignore the process that causes missing data if the missing data are `missing at random' and the observed data are `observed at random', 
		but these inferences are generally conditional on the observed pattern of missing data. 
		When making direct-likelihood or Bayesian inferences about $\theta$, 
		it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `distinct' from $\theta$. 
		These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.
	},
}

@InBook{
	Lib-Missing-Data-Arbuckle-1996
	,
	author    = {
		Arbuckle, James L.
	},
	booktitle = {
		Advanced structural equation modeling
	},
	date      = {
		1996
	},
	title     = {
		Full information estimation in the presence of incomplete data
	},
	doi       = {
		10.4324/9781315827414
	},
	editor    = {
		Marcoulides, George A. and Schumacker, Randall E.
	},
	publisher = {
		Psychology Press
	},
	file = {},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
}

@Article{
	Lib-Missing-Data-Schafer-1998,
	author       = {
		Schafer, Joseph L. 
		and 
		Olsen, Maren K.
	},
	date         = {
		1998-10
	},
	journaltitle = {
		Multivariate Behavioral Research
	},
	title        = {
		Multiple imputation for multivariate missing-data problems: A data analyst's perspective
	},
	doi          = {
		10.1207/s15327906mbr3304_5
	},
	number       = {
		4
	},
	pages        = {
		545--571
	},
	volume       = {
		33
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1207%2Fs15327906mbr3304_5.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Analyses of multivariate data are frequently hampered by missing values. 
		Until recently, 
		the only missing-data methods available to most data analysts have been relatively ad hoc practices such as listwise deletion. 
		Recent dramatic advances in theoretical and computational statistics, 
		however, 
		have produced anew generation of flexible procedures with a sound statistical basis.
		These procedures involve multiple imputation (Rubin, 1987), 
		a simulation technique that replaces each missing datum with a set of $m > 1$ plausible values. 
		The $m$ versions of the complete data are analyzed by standard complete-data methods,
		and the results are combined using simple rules to yield estimates, 
		standard errors, 
		and $p$-values that formally incorporate missing-data uncertainty. 
		New computational algorithms and software described in a recent book (Schafer, 1997a) allow us to create proper multiple imputations in complex multivariate settings. 
		This article reviews the key ideas of multiple imputation, 
		discusses the software programs currently available, 
		and demonstrates their use on data from the Adolescent Alcohol Prevention Trial (Hansen \& Graham, 1991).
	},
}

@Article{
	Lib-Missing-Data-Yuan-2000
	,
	author       = {
		Yuan, Ke-Hai 
		and 
		Bentler, Peter M.
	},
	date         = {
		2000-08
	},
	journaltitle = {
		Sociological Methodology
	},
	title        = {
		Three likelihood-based methods for mean and covariance structure analysis with nonnormal missing data
	},
	doi          = {
		10.1111/0081-1750.00078
	},
	number       = {
		1
	},
	pages        = {
		165--200
	},
	volume       = {
		30
	},
	publisher    = {
		{SAGE} Publications
	},
	file = {
		references/10.1111%2F0081-1750.00078.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Survey and longitudinal studies in the social and behavioral sciences generally contain missing data. 
		Mean and covariance structure models play an important role in analyzing such data. 
		Two promising methods for dealing with missing data are a direct maximum-likelihood and a two-stage approach based on the unstructured mean and covariance estimates obtained by the EM-algorithm. 
		Typical assumptions under these two methods are ignorable nonresponse and normality of data. 
		However, 
		data sets in social and behavioral sciences are seldom normal,
		and experience with these procedures indicates that normal theory based methods for nonnormal data very often lead to incorrect model evaluations. 
		By dropping the normal distribution assumption, 
		we develop more accurate procedures for model inference. 
		Based on the theory of generalized estimating equations, 
		a way to obtain consistent standard errors of the two-stage estimates is given. 
		The asymptotic efficiencies of different estimators are compared under various assumptions. 
		We also propose a minimum chi-square approach and show that the estimator obtained by this approach is asymptotically at least as efficient as the two likelihood-based estimators for either normal or nonnormal data. 
		The major contribution of this paper is that for each estimator, 
		we give a test statistic whose asymptotic distribution is chisquare as long as the underlying sampling distribution enjoys finite fourth-order moments. 
		We also give a characterization for each of the two likelihood ratio test statistics when the underlying distribution is nonnormal. 
		Modifications to the likelihood ratio statistics are also given. 
		Our working assumption is that the missing data mechanism is missing completely at random. 
		Examples and Monte Carlo studies indicate that, 
		for commonly encountered nonnormal distributions, 
		the procedures developed in this paper are quite reliable even for samples with missing data that are missing at random.
	},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Psychological Methods
% Special Issue

@Article{
	Lib-Missing-Data-Collins-2001
	,
	author       = {
		Collins, Linda M. 
		and 
		Schafer, Joseph L. 
		and 
		Kam, Chi-Ming
	},
	date         = {
		2001
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		A comparison of inclusive and restrictive strategies in modern missing data procedures
	},
	doi          = {
		10.1037/1082-989x.6.4.330
	},
	number       = {
		4
	},
	pages        = {
		330--351
	},
	volume       = {
		6
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F1082-989x.6.4.330.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Two classes of modem missing data procedures,
		maximum likelihood (ML) and multiple imputation (MI),
		tend to yield similar results when implemented in comparable ways.
		In either approach,
		it is possible to include auxiliary variables solely for the purpose of improving the missing data procedure.
		A simulation was presented to assess the potential costs and benefits of a restrictive strategy,
		which makes minimal use of auxiliary variables,
		versus an inclusive strategy,
		which makes liberal use of such variables.
		The simulation showed that the inclusive strategy is to be greatly preferred.
		With an inclusive strategy not only is there a reduced chance of inadvertently omitting an important cause of missingness,
		there is also the possibility of noticeable gains in terms of increased efficiency and reduced bias,
		with only minor costs.
		As implemented in currently available software,
		the ML approach tends to encourage the use of a restrictive strategy,
		whereas the MI approach makes it relatively simple to use an inclusive strategy.
	},
}

@Article{
	Lib-Missing-Data-Enders-2001a
	,
	author       = {
		Craig K. Enders
	},
	date         = {
		2001
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		The impact of nonnormality on full information maximum-likelihood estimation for structural equation models with missing data
	},
	doi          = {
		10.1037/1082-989x.6.4.352
	},
	number       = {
		4
	},
	pages        = {
		352--370
	},
	volume       = {
		6
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F1082-989x.6.4.352.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		A Monte Carlo simulation examined full information maximum-likelihood estimation (FIML) in structural equation models with nonnormal indicator variables. 
		The impacts of 4 independent variables were examined (missing data algorithm, 
		missing data rate, 
		sample size, 
		and distribution shape) on 4 outcome measures (parameter estimate bias, 
		parameter estimate efficiency, 
		standard error coverage, 
		and model rejection rates). 
		Across missing completely at random and missing at random patterns, 
		FIML parameter estimates involved less bias and were generally more efficient than those of ad hoc missing data techniques. 
		However, 
		similar to complete-data maximum-likelihood estimation in structural equation modeling, 
		standard errors were negatively biased and model rejection rates were inflated. 
		Simulation results suggest that recently developed correctives for missing data (e.g., rescaled statistics and the bootstrap) can mitigate problems that stem from nonnormal data.
	},
}

@Article{
	Lib-Missing-Data-Sinharay-2001
	,
	author       = {
		Sinharay, Sandip 
		and 
		Stern, Hal S. 
		and 
		Russell, Daniel
	},
	date         = {
		2001
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		The use of multiple imputation for the analysis of missing data
	},
	doi          = {
		10.1037/1082-989x.6.4.317
	},
	number       = {
		4
	},
	pages        = {
		317--329
	},
	volume       = {
		6
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F1082-989x.6.4.317.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		This article provides a comprehensive review of multiple imputation (MI), 
		a technique for analyzing data sets with missing values.
		Formally, MI is the process of replacing each missing data point with a set of $m > 1$ plausible values to generate $m$ complete data sets. 
		These complete data sets are then analyzed by standard statistical software, 
		and the results combined, 
		to give parameter estimates and standard errors that take into account the uncertainty due to the missing data values. 
		This article introduces the idea behind MI, 
		discusses the advantages of MI over existing techniques for addressing missing data, 
		describes how to do MI for real problems, 
		reviews the software available to implement MI, 
		and discusses the results of a simulation study aimed at finding out how assumptions regarding the imputation model affect the parameter estimates provided by MI.
	},
}

@Article{
	Lib-Missing-Data-West-2001
	,
	author       = {
		West, Stephen G.
	},
	date         = {
		2001
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		New approaches to missing data in psychological research: Introduction to the special section
	},
	doi          = {
		10.1037/1082-989x.6.4.315
	},
	number       = {
		4
	},
	pages        = {
		315--316
	},
	volume       = {
		6
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F1082-989x.6.4.315.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Traditional approaches to missing data (e.g., listwise deletion) can lead to less than optimal results in terms of bias,
		statistical power,
		or both.
		This article introduces the 3 articles in the special section of Psychological Methods,
		which consider multiple imputation and maximum-likelihood methods,
		new approaches to missing data that can often yield improved results.
		Computer software is now available to implement these new methods.
	},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@Article{
	Lib-Missing-Data-Enders-2001b
	,
	author       = {
		Enders, Craig K.
	},
	date         = {
		2001-01
	},
	journaltitle = {
		Structural Equation Modeling: A Multidisciplinary Journal
	},
	title        = {
		A primer on maximum likelihood algorithms available for use with missing data
	},
	doi          = {
		10.1207/s15328007sem0801_7
	},
	number       = {
		1
	},
	pages        = {
		128--141
	},
	volume       = {
		8
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1207%2Fs15328007sem0801_7.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Maximum likelihood algorithms for use with missing data are becoming commonplace in microcomputer packages. 
		Specifically, 
		3 maximum likelihood algorithms are currently available in existing software packages: 
		the multiple-group approach, 
		full information maximum likelihood estimation, 
		and the EM algorithm. 
		Although they belong to the same family of estimator,
		confusion appears to exist over the differences among the 3 algorithms. 
		This article provides a comprehensive, 
		nontechnical overview of the 3 maximum likelihood algorithms. 
		Multiple imputation, 
		which is frequently used in conjunction with the EM algorithm,
		is also discussed.
	},
}

@Article{
	Lib-Missing-Data-Schafer-2002,
	author       = {
		Schafer, Joseph L. 
		and 
		Graham, John W.
	},
	date         = {
		2002
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		Missing data: Our view of the state of the art
	},
	doi          = {
		10.1037/1082-989x.7.2.147
	},
	number       = {
		2
	},
	pages        = {
		147--177
	},
	volume       = {
		7
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F1082-989x.7.2.147.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Statistical procedures for missing data have vastly improved, 
		yet misconception and unsound practice still abound. 
		The authors frame the missing-data problem, 
		review methods, 
		offer advice, 
		and raise issues that remain unresolved. 
		They clear up common misunderstandings regarding the missing at random (MAR) concept.
		They summarize the evidence against older procedures and, 
		with few exceptions, 
		discourage their use. 
		They present, 
		in both technical and practical language, 
		2 general approaches that come highly recommended: 
		maximum likelihood (ML) and Bayesian multiple imputation (MI). 
		Newer developments are discussed, 
		including some for dealing with missing data that are not MAR. 
		Although not yet in the mainstream, 
		these procedures may eventually extend the ML and MI methods that currently represent the state of the art.
	},
}

@Article{
	Lib-Missing-Data-Peugh-2004
	,
	author       = {
		Peugh, James L. 
		and 
		Enders, Craig K.
	},
	date         = {
		2004-12
	},
	journaltitle = {
		Review of Educational Research
	},
	title        = {
		Missing data in educational research: A review of reporting practices and suggestions for improvement
	},
	doi          = {
		10.3102/00346543074004525
	},
	number       = {
		4
	},
	pages        = {
		525--556
	},
	volume       = {
		74
	},
	publisher    = {
		American Educational Research Association ({AERA})
	},
	file = {
		references/10.3102%2F00346543074004525.pdf
	},
	library = {},
	keywords = {
		EM algorithm, 
		maximum likelihood estimation, 
		missing data, 
		multiple imputation, 
		NORM
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Missing data analyses have received considerable recent attention in the methodological literature, and two ``modern'' methods, 
		multiple imputation and maximum likelihood estimation, 
		are recommended. 
		The goals of this article are to (a) provide an overview of missing-data theory, 
		maximum likelihood estimation, 
		and multiple imputation; 
		(b) conduct a methodological review of missing-data reporting practices in 23 applied research journals; 
		and (c) provide a demonstration of multiple imputation and maximum likelihood estimation using the Longitudinal Study of American Youth data. 
		The results indicated that explicit discussions of missing data increased substantially between 1999 and 2003, 
		but the use of maximum likelihood estimation or multiple imputation was rare; 
		the studies relied almost exclusively on listwise and pairwise deletion.
	},
}

@Article{
	Lib-Missing-Data-Graham-2009
	,
	author       = {
		Graham, John W.
	},
	date         = {
		2009-01
	},
	journaltitle = {
		Annual Review of Psychology
	},
	title        = {
		Missing data analysis: Making it work in the real world
	},
	doi          = {
		10.1146/annurev.psych.58.110405.085530
	},
	number       = {
		1
	},
	pages        = {
		549--576
	},
	volume       = {
		60
	},
	publisher    = {
		Annual Reviews
	},
	file = {
		references/10.1146%2Fannurev.psych.58.110405.085530.pdf
	},
	library = {},
	keywords = {
		multiple imputation, 
		maximum likelihood, 
		attrition, 
		nonignorable missingness, 
		planned missingness 
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		This review presents a practical summary of the missing data literature, 
		including a sketch of missing data theory and descriptions of normal-model multiple imputation (MI) and maximum likelihood methods. 
		Practical missing data analysis issues are discussed, 
		most notably the inclusion of auxiliary variables for improving power and reducing bias. 
		Solutions are given for missing data challenges such as handling longitudinal, 
		categorical, 
		and clustered data with normal-model MI; 
		including interactions in the missing data model; 
		and handling large numbers of variables. 
		The discussion of attrition and nonignorable missingness emphasizes the need for longitudinal diagnostics and for reducing the uncertainty about the missing data mechanism under attrition. 
		Strategies suggested for reducing attrition bias include using auxiliary variables, 
		collecting follow-up data on a sample of those initially missing, 
		and collecting data on intent to drop out. Suggestions are given for moving forward with research on missing data and attrition.
	},
}

@Article{
	Lib-Missing-Data-Cheema-2014
	,
	author       = {
		Cheema, Jehanzeb R.
	},
	date         = {
		2014-12
	},
	journaltitle = {
		Review of Educational Research
	},
	title        = {
		A review of missing data handling methods in education research
	},
	doi          = {
		10.3102/0034654314532697
	},
	number       = {
		4
	},
	pages        = {
		487--508
	},
	volume       = {84},
	publisher    = {
		American Educational Research Association ({AERA})
	},
	file = {
		references/10.3102%2F0034654314532697.pdf
	},
	library = {},
	keywords = {
		missing data, 
		imputation, 
		education research, 
		listwise deletion, 
		missing value analysis
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Missing data are a common occurrence in survey-based research studies in education, and the way missing values are handled can significantly affect the results of analyses based on such data. 
		Despite known problems with performance of some missing data handling methods, 
		such as mean imputation, 
		many researchers in education continue to use those methods as a quick fix. 
		This study reviews the current literature on missing data handling methods within the special context of education research to summarize the pros and cons of various methods and provides guidelines for future research in this area.
	},
}

@Article{
	Lib-Missing-Data-Schouten-2018a
	,
	author       = {
		Schouten, Rianne Margaretha 
		and 
		Lugtig, Peter 
		and 
		Vink, Gerko
	},
	date         = {
		2018-07
	},
	journaltitle = {
		Journal of Statistical Computation and Simulation
	},
	title        = {
		Generating missing values for simulation purposes: A multivariate amputation procedure
	},
	doi          = {
		10.1080/00949655.2018.1491577
	},
	number       = {
		15
	},
	pages        = {
		2909--2930
	},
	volume       = {
		88
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1080%2F00949655.2018.1491577.pdf
	},
	library = {},
	keywords = {
		missing data,
		multiple imputation,
		multivariate amputation,
		evaluation
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Missing data form a ubiquitous problem in scientific research, 
		especially since most statistical analyses require complete data. 
		To evaluate the performance of methods dealing with missing data, 
		researchers perform simulation studies. 
		An important aspect of these studies is the generation of missing values in a simulated, 
		complete data set: 
		the amputation procedure. 
		We investigated the methodological validity and statistical nature of both the current amputation practice and a newly developed and implemented multivariate amputation procedure. 
		We found that the current way of practice may not be appropriate for the generation of intuitive and reliable missing data problems. 
		The multivariate amputation procedure, 
		on the other hand, 
		generates reliable amputations and allows for a proper regulation of missing data problems. 
		The procedure has additional features to generate any missing data scenario precisely as intended. 
		Hence, 
		the multivariate amputation procedure is an efficient method to accurately evaluate missing data methodology.
	},
}

@Article{
	Lib-Missing-Data-Schouten-2018b
	,
	author       = {
		Schouten, Rianne Margaretha 
		and 
		Vink, Gerko
	},
	date         = {
		2018-10
	},
	journaltitle = {
		Sociological Methods {\&} Research
	},
	title        = {
		The dance of the mechanisms: How observed information influences the validity of missingness assumptions
	},
	doi          = {
		10.1177/0049124118799376
	},
	number       = {
		3
	},
	pages        = {
		1243--1258
	},
	volume       = {
		50
	},
	publisher    = {
		{SAGE} Publications
	},
	file = {
		references/10.1177%2F0049124118799376.pdf
	},
	library = {},
	keywords = {
		missing data methodology, 
		missingness assumptions, 
		multivariate amputation
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		Missing data in scientific research go hand in hand with assumptions about the nature of the missingness.
		When dealing with missing values,
		a set of beliefs has to be formulated about the extent to which the observed data may also hold for the missing parts of the data.
		It is vital that the validity of these missingness assumptions is verified, tested, and that assumptions are adjusted when necessary.
		In this article,
		we demonstrate how observed data structures could a priori indicate whether it is likely that our beliefs about the missingness can be trusted.
		To this end,
		we simulate complete data and generate missing values according several types of MCAR, MAR, and MNAR mechanisms.
		We demonstrate that in scenarios where the data correlations are either low or very substantial,
		strictly different mechanisms yield equivalent statistical inferences.
		In addition,
		we show that the choice of quantity of scientific interest together with the distribution of the nonresponse govern the validity of the missingness assumptions.
	},
}

@Article{
	Lib-Missing-Data-Savalei-2021
	,
	author       = {
		Savalei, Victoria 
		and 
		Rosseel, Yves
	},
	date         = {
		2021-10
	},
	journaltitle = {
		Structural Equation Modeling: A Multidisciplinary Journal
	},
	title        = {
		Computational options for standard errors and test statistics with incomplete normal and nonnormal data in {SEM}
	},
	doi          = {
		10.1080/10705511.2021.1877548
	},
	number       = {
		2
	},
	pages        = {
		163--181
	},
	volume       = {
		29
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1080%2F10705511.2021.1877548.pdf
	},
	library = {},
	keywords = {
		incomplete data,
		nonnormal data,
		robust corrections,
		software implementation
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Missing-Data
	},
	abstract     = {
		This article provides an overview of different computational options for inference following normal theory maximum likelihood (ML) estimation in structural equation modeling (SEM) with incomplete normal and nonnormal data. 
		Complete data are covered as a special case. 
		These computational options include whether the information matrix is observed or expected, 
		whether the observed information matrix is estimated numerically or using an analytic asymptotic approximation, 
		and whether the information matrix and the outer product matrix of the score vector are evaluated at the saturated or at the structured estimates. 
		A variety of different standard errors and robust test statistics become possible by varying these options. 
		We review the asymptotic properties of these computational variations, 
		and we show how to obtain them using lavaan in R. 
		We hope that this article will encourage methodologists to study the impact of the available computational options on the performance of standard errors and test statistics in SEM.
	},
}

@Comment{jabref-meta: databaseType:biblatex;}

% https://bookdown.org/mwheymans/bookmi/
