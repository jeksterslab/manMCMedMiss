% Encoding: US-ASCII

@Article{
	Lib-Mediation-Bootstrap-Bollen-1990
	,
	author       = {
		Bollen, Kenneth A. 
		and 
		Stine, Robert
	},
	date         = {
		1990
	},
	journaltitle = {
		Sociological Methodology
	},
	title        = {
		Direct and indirect effects: Classical and bootstrap estimates of variability
	},
	doi          = {
		10.2307/271084
	},
	pages        = {
		115
	},
	volume       = {
		20
	},
	publisher    = {
		{JSTOR}
	},
	file = {
		references/10.2307%2F271084.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		The decomposition of effects in structural equation models has been of considerable interest to social scientists. 
		Finite-sample or asymptotic results for the sampling distribution of estimators of direct effects are widely available. 
		Statistical inferences about indirect effects have relied exclusively on asymptotic methods which assume that the limiting distribution of the estimator is normal, 
		with a standard error derived from the delta method. 
		We examine bootstrap procedures as another way to generate standard errors and confidence intervals and to estimate the sampling distributions of estimators of direct and indirect effects. 
		We illustrate the classical and the bootstrap methods with three empirical examples. 
		We find that in a moderately large sample, the bootstrap distribution of an estimator is close to that assumed with the classical and delta methods but that in small samples, there are some differences. 
		Bootstrap methods provide a check on the classical and delta methods when the latter are applied under less than ideal conditions.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Shrout-2002
	,
	author       = {
		Shrout, Patrick E. 
		and 
		Bolger, Niall
	},
	date         = {
		2002
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		Mediation in experimental and nonexperimental studies: New procedures and recommendations
	},
	doi          = {
		10.1037/1082-989x.7.4.422
	},
	number       = {
		4
	},
	pages        = {
		422--445
	},
	volume       = {
		7
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2F1082-989x.7.4.422.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Mediation is said to occur when a causal effect of some variable $X$ on an outcome $Y$ is explained by some intervening variable $M$. 
		The authors recommend that with small to moderate samples, 
		bootstrap methods (B. Efron \& R. Tibshirani, 1993) be used to assess mediation. 
		Bootstrap tests are powerful because they detect that the sampling distribution of the mediated effect is skewed away from 0. 
		They argue that R. M. Baron and D. A. Kenny's (1986) recommendation of first testing the $X \to Y$ association for statistical significance should not be a requirement when there is a priori belief that the effect size is small or suppression is a possibility. 
		Empirical examples and computer setups for bootstrap analyses are provided.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Preacher-2004
	,
	author       = {
		Preacher, Kristopher J. 
		and 
		Hayes, Andrew F.
	},
	date         = {
		2004-11
	},
	journaltitle = {
		Behavior Research Methods, Instruments, \& Computers
	},
	title        = {
		{SPSS} and {SAS} procedures for estimating indirect effects in simple mediation models
	},
	doi          = {
		10.3758/bf03206553
	},
	number       = {
		4
	},
	pages        = {
		717--731
	},
	volume       = {
		36
	},
	publisher    = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.3758%2Fbf03206553.pdf
	},
	library = {},
	keywords = {
		life satisfaction,
		indirect effect,
		mediation analysis,
		cognitive therapy,
		Sobel test
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Researchers often conduct mediation analysis in order to indirectly assess the effect of a proposed cause on some outcome through a proposed mediator. 
		The utility of mediation analysis stems from its ability to go beyond the merely descriptive to a more functional understanding of the relationships among variables. 
		A necessary component of mediation is a statistically and practically significant indirect effect. 
		Although mediation hypotheses are frequently explored in psychological research, 
		formal significance tests of indirect effects are rarely conducted. 
		After a brief overview of mediation, we argue the importance of directly testing the significance of indirect effects and provide SPSS and SAS macros that facilitate estimation of the indirect effect with a normal theory approach and a bootstrap approach to obtaining confidence intervals, 
		as well as the traditional approach advocated by Baron and Kenny (1986). 
		We hope that this discussion and the macros will enhance the frequency of formal mediation tests in the psychology literature. 
		Electronic copies of these macros may be downloaded from the Psychonomic Societyâ€™s Web archive at www.psychonomic.org/archive/.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Cheung-2007-07
	,
	author       = {
		Cheung, Gordon W. 
		and 
		Lau, Rebecca S.
	},
	date         = {
		2007-07
	},
	journaltitle = {
		Organizational Research Methods
	},
	title        = {
		Testing mediation and suppression effects of latent variables
	},
	doi          = {
		10.1177/1094428107300343
	},
	number       = {
		2
	},
	pages        = {
		296--325
	},
	volume       = {
		11
	},
	publisher    = {
		{SAGE} Publications
	},
	file = {
		references/10.1177%2F1094428107300343.pdf
	},
	library = {},
	keywords = {
		mediating effects, 
		suppression effects, 
		structural equation modeling
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Because of the importance of mediation studies, 
		researchers have been continuously searching for the best statistical test for mediation effect. 
		The approaches that have been most commonly employed include those that use zero-order and partial correlation, 
		hierarchical regression models, 
		and structural equation modeling (SEM). 
		This study extends MacKinnon and colleagues (MacKinnon, Lockwood, Hoffmann, West, \& Sheets, 2002; MacKinnon, Lockwood, \& Williams, 2004, MacKinnon, Warsi, \& Dwyer, 1995) works by conducting a simulation that examines the distribution of mediation and suppression effects of latent variables with SEM, 
		and the properties of confidence intervals developed from eight different methods. 
		Results show that SEM provides unbiased estimates of mediation and suppression effects, and that the bias-corrected bootstrap confidence intervals perform best in testing for mediation and suppression effects. 
		Steps to implement the recommended procedures with Amos are presented.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Cheung-2007-05
	,
	author       = {
		Cheung, Mike W.-L.
	},
	date         = {
		2007-05
	},
	journaltitle = {
		Structural Equation Modeling: A Multidisciplinary Journal
	},
	title        = {
		Comparison of approaches to constructing confidence intervals for mediating effects using structural equation models
	},
	doi          = {
		10.1080/10705510709336745
	},
	number       = {
		2
	},
	pages        = {
		227--246
	},
	volume       = {
		14
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1080%2F10705510709336745.pdf
	},
	library = {},
	keywords = {
		mediation, 
		bootstrapping
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Mediators are variables that explain the association between an independent variable and a dependent variable. 
		Structural equation modeling (SEM) is widely used to test models with mediating effects. 
		This article illustrates how to construct confidence intervals (CIs) of the mediating effects for a variety of models in SEM. 
		Specifically, mediating models with 1 mediator, 2 intermediate mediators, 2 specific mediators, and 1 mediator in 2 independent groups are illustrated. 
		By using phantom variables (Rindskopf, 1984), 
		a Wald CI, 
		percentile bootstrap CI, 
		bias-corrected bootstrap CI, 
		and a likelihood-based CI on the mediating effect are easily constructed with some existing SEM packages, 
		such as LISREL, Mplus, and Mx. 
		Monte Carlo simulation studies are used to compare the coverage probabilities of these CIs. 
		The results show that the coverage probabilities of these CIs are comparable when the mediating effect is large or when the sample size is large. 
		However, when the mediating effect and the sample size are both small, the bootstrap CI and likelihood-based CI are preferred over the Wald CI. 
		Extensions of this SEM approach for future research are discussed.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Taylor-2007
	,
	author       = {
		Taylor, Aaron B. 
		and 
		MacKinnon, David P. 
		and 
		Tein, Jenn-Yun
	},
	date         = {
		2007-07
	},
	journaltitle = {
		Organizational Research Methods
	},
	title        = {
		Tests of the three-path mediated effect
	},
	doi          = {
		10.1177/1094428107300344
	},
	number       = {
		2
	},
	pages        = {
		241--269
	},
	volume       = {
		11
	},
	publisher    = {
		{SAGE} Publications
	},
	file = {
		references/10.1177%2F1094428107300344.pdf
	},
	library = {},
	keywords = {
		mediation, 
		bootstrapping
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		In a three-path mediational model, 
		two mediators intervene in a series between an independent and a dependent variable. 
		Methods of testing for mediation in such a model are generalized from the more often used single-mediator model. 
		Six such methods are introduced and compared in a Monte Carlo study in terms of their Type I error, power, and coverage. 
		Based on its results, the joint significance test is preferred when only a hypothesis test is of interest. 
		The percentile bootstrap and bias-corrected bootstrap are preferred when a confidence interval on the mediated effect is desired, 
		with the latter having more power but also slightly inflated Type I error in some conditions.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Preacher-2008
	,
	author       = {
		Preacher, Kristopher J. 
		and 
		Hayes, Andrew F.
	},
	date         = {
		2008-08
	},
	journaltitle = {
		Behavior Research Methods
	},
	title        = {
		Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models
	},
	doi          = {
		10.3758/brm.40.3.879
	},
	number       = {
		3
	},
	pages        = {
		879--891
	},
	volume       = {
		40
	},
	publisher    = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.3758%2Fbrm.40.3.879.pdf
	},
	library = {},
	keywords = {
		indirect effect,
		structural equation modeling,
		residual covariance,
		total indirect effect,
		multiple mediator model
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Hypotheses involving mediation are common in the behavioral sciences. 
		Mediation exists when a predictor affects a dependent variable indirectly through at least one intervening variable, or mediator. 
		Methods to assess mediation involving multiple simultaneous mediators have received little attention in the methodological literature despite a clear need. 
		We provide an overview of simple and multiple mediation and explore three approaches that can be used to investigate indirect processes, 
		as well as methods for contrasting two or more mediators within a single model. 
		We present an illustrative example, assessing and contrasting potential mediators of the relationship between the helpfulness of socialization agents and job satisfaction. 
		We also provide SAS and SPSS macros, 
		as well as Mplus and LISREL syntax, 
		to facilitate the use of these methods in applications.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Cheung-2009
	,
	author       = {
		Cheung, Mike W.-L.
	},
	date         = {
		2009-05
	},
	journaltitle = {
		Behavior Research Methods
	},
	title        = {
		Comparison of methods for constructing confidence intervals of standardized indirect effects
	},
	doi          = {
		10.3758/brm.41.2.425
	},
	number       = {
		2
	},
	pages        = {
		425--438
	},
	volume       = {
		41
	},
	publisher    = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.3758%2Fbrm.41.2.425.pdf
	},
	library = {},
	keywords = {
		mediation analysis,
		coverage probability,
		structural equation modeling approach
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Mediation models are often used as a means to explain the psychological mechanisms between an independent and a dependent variable in the behavioral and social sciences. 
		A major limitation of the unstandardized indirect effect calculated from raw scores is that it cannot be interpreted as an effect-size measure. 
		In contrast, the standardized indirect effect calculated from standardized scores can be a good candidate as a measure of effect size because it is scale invariant. 
		In the present article, 11 methods for constructing the confidence intervals (CIs) of the standardized indirect effects were evaluated via a computer simulation. 
		These included six Wald CIs, three bootstrap CIs, one likelihood-based CI, and the PRODCLIN CI. 
		The results consistently showed that the percentile bootstrap, the bias-corrected bootstrap, and the likelihood-based approaches had the best coverage probability. 
		Mplus, LISREL, and Mx syntax were included to facilitate the use of these preferred methods in applied settings. Future issues on the use of the standardized indirect effects are discussed.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Hayes-2009
	,
	author       = {
		Hayes, Andrew F.
	},
	date         = {
		2009-12
	},
	journaltitle = {
		Communication Monographs
	},
	title        = {
		Beyond {Baron} and {Kenny}: Statistical mediation analysis in the new millennium
	},
	doi          = {
		10.1080/03637750903310360
	},
	number       = {
		4
	},
	pages        = {
		408--420
	},
	volume       = {
		76
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1080%2F03637750903310360.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Understanding communication processes is the goal of most communication researchers. 
		Rarely are we satisfied merely ascertaining whether messages have an effect on some outcome of focus in a specific context. 
		Instead, we seek to understand how such effects come to be. 
		What kinds of causal sequences does exposure to a message initiate? 
		What are the causal pathways through which a message exerts its effect? 
		And what role does communication play in the transmission of the effects of other variables over time and space? 
		Numerous communication models attempt to describe the mechanism through which messages or other communication-related variables transmit their effects or intervene between two other variables in a causal model. 
		The communication literature is replete with tests of such models.
		
		Over the years, methods used to test such process models have grown in sophistication. 
		An example includes the rise of structural equation modeling (SEM), which allows investigators to examine how well a process model that links some focal variable X to some outcome Y through one or more intervening pathways fits the observed data. 
		Yet frequently, the analytical choices communication researchers make when testing intervening variables models are out of step with advances made in the statistical methods literature. 
		My goal here is to update the field on some of these new advances. 
		While at it, I challenge some conventional wisdom and nudge the field toward a more modern way of thinking about the analysis of intervening variable effects.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Biesanz-2010
	,
	author       = {
		Biesanz, Jeremy C. 
		and 
		Falk, Carl F. 
		and 
		Savalei, Victoria
	},
	date         = {
		2010-08
	},
	journaltitle = {
		Multivariate Behavioral Research
	},
	title        = {
		Assessing mediational models: Testing and interval estimation for indirect effects
	},
	doi          = {
		10.1080/00273171.2010.498292
	},
	number       = {
		4
	},
	pages        = {
		661--701
	},
	volume       = {
		45
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1080%2F00273171.2010.498292.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Theoretical models specifying indirect or mediated effects are common in the social sciences. 
		An indirect effect exists when an independent variable's influence on the dependent variable is mediated through an intervening variable. 
		Classic approaches to assessing such mediational hypotheses (Baron \& Kenny, 1986; Sobel, 1982) have in recent years been supplemented by computationally intensive methods such as bootstrapping, 
		the distribution of the product methods, 
		and hierarchical Bayesian Markov chain Monte Carlo (MCMC) methods. 
		These different approaches for assessing mediation are illustrated using data from Dunn, Biesanz, Human, and Finn (2007). 
		However, little is known about how these methods perform relative to each other, particularly in more challenging situations, 
		such as with data that are incomplete and/or nonnormal. 
		This article presents an extensive Monte Carlo simulation evaluating a host of approaches for assessing mediation. 
		We examine Type I error rates, power, and coverage. 
		We study normal and nonnormal data as well as complete and incomplete data. In addition, we adapt a method, 
		recently proposed in statistical literature, 
		that does not rely on confidence intervals (CIs) to test the null hypothesis of no indirect effect. 
		The results suggest that the new inferential method--the partial posterior p value--slightly outperforms existing ones in terms of maintaining Type I error rates while maximizing power, 
		especially with incomplete data. 
		Among confidence interval approaches, 
		the bias-corrected accelerated (BCa) bootstrapping approach often has inflated Type I error rates and inconsistent coverage and is not recommended.
		In contrast, the bootstrapped percentile confidence interval and the hierarchical Bayesian MCMC method perform best overall,
		maintaining Type I error rates,
		exhibiting reasonable power,
		and producing stable and accurate coverage rates.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Fritz-2012
	,
	author       = {
		Fritz, Matthew S. 
		and 
		Taylor, Aaron B. 
		and 
		MacKinnon, David P.
	},
	date         = {
		2012-02
	},
	journaltitle = {
		Multivariate Behavioral Research
	},
	title        = {
		Explanation of two anomalous results in statistical mediation analysis
	},
	doi          = {
		10.1080/00273171.2012.640596
	},
	number       = {
		1
	},
	pages        = {
		61--87
	},
	volume       = {
		47
	},
	publisher    = {
		Informa {UK} Limited
	},
	file = {
		references/10.1080%2F00273171.2012.640596.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Previous studies of different methods of testing mediation models have consistently found two anomalous results. 
		The first result is elevated Type I error rates for the bias-corrected and accelerated bias-corrected bootstrap tests not found in nonresampling tests or in resampling tests that did not include a bias correction. 
		This is of special concern as the bias-corrected bootstrap is often recommended and used due to its higher statistical power compared with other tests. 
		The second result is statistical power reaching an asymptote far below 1.0 and in some conditions even declining slightly as the size of the relationship between X and M, a, increased. 
		Two computer simulations were conducted to examine these findings in greater detail. Results from the first simulation found that the increased Type I error rates for the bias-corrected and accelerated bias-corrected bootstrap are a function of an interaction between the size of the individual paths making up the mediated effect and the sample size, 
		such that elevated Type I error rates occur when the sample size is small and the effect size of the nonzero path is medium or larger. 
		Results from the second simulation found that stagnation and decreases in statistical power as a function of the effect size of the a path occurred primarily when the path between M and Y, b, was small. 
		Two empirical mediation examples are provided using data from a steroid prevention and health promotion program aimed at high school football players (Athletes Training and Learning to Avoid Steroids; Goldberg et al., 1996), 
		one to illustrate a possible Type I error for the bias-corrected bootstrap test and a second to illustrate a loss in power related to the size of a. 
		Implications of these findings are discussed.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Taylor-2012
	,
	author       = {
		Taylor, Aaron B. 
		and 
		MacKinnon, David P.
	},
	date         = {
		2012-02
	},
	journaltitle = {
		Behavior Research Methods
	},
	title        = {
		Four applications of permutation methods to testing a single-mediator model
	},
	doi          = {
		10.3758/s13428-011-0181-x
	},
	number       = {
		3
	},
	pages        = {
		806--844
	},
	volume       = {
		44
	},
	publisher    = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.3758%2Fs13428-011-0181-x.pdf
	},
	library = {},
	keywords = {
		mediation, 
		bootstrapping, 
		permutation, 
		Bayes
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Four applications of permutation tests to the single-mediator model are described and evaluated in this study. 
		Permutation tests work by rearranging data in many possible ways in order to estimate the sampling distribution for the test statistic.
		The four applications to mediation evaluated here are the permutation test of ab, 
		the permutation joint significance test, and the noniterative and iterative permutation confidence intervals for ab. 
		A Monte Carlo simulation study was used to compare these four tests with the four best available tests for mediation found in previous research: 
		the joint significance test, 
		the distribution of the product test, 
		and the percentile and bias-corrected bootstrap tests. 
		We compared the different methods on Type I error, 
		power, 
		and confidence interval coverage. 
		The noniterative permutation confidence interval for ab was the best performer among the new methods. 
		It successfully controlled Type I error, 
		had power nearly as good as the most powerful existing methods, 
		and had better coverage than any existing method. 
		The iterative permutation confidence interval for ab had lower power than do some existing methods, 
		but it performed better than any other method in terms of coverage. 
		The permutation confidence interval methods are recommended when estimating a confidence interval is a primary concern. 
		SPSS and SAS macros that estimate these confidence intervals are provided.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Hayes-2013
	,
	author       = {
		Hayes, Andrew F. 
		and 
		Scharkow, Michael
	},
	date         = {
		2013-08
	},
	journaltitle = {
		Psychological Science
	},
	title        = {
		The relative trustworthiness of inferential tests of the indirect effect in statistical mediation analysis
	},
	doi          = {
		10.1177/0956797613480187
	},
	number       = {
		10
	},
	pages        = {
		1918--1927
	},
	volume       = {
		24
	},
	publisher    = {
		{SAGE} Publications
	},
	abstract     = {
		A content analysis of 2 years of Psychological Science articles reveals inconsistencies in how researchers make inferences about indirect effects when conducting a statistical mediation analysis. 
		In this study, we examined the frequency with which popularly used tests disagree, whether the method an investigator uses makes a difference in the conclusion he or she will reach, and whether there is a most trustworthy test that can be recommended to balance practical and performance considerations. 
		We found that tests agree much more frequently than they disagree, but disagreements are more common when an indirect effect exists than when it does not. 
		We recommend the bias-corrected bootstrap confidence interval as the most trustworthy test if power is of utmost concern, although it can be slightly liberal in some circumstances. 
		Investigators concerned about Type I errors should choose the Monte Carlo confidence interval or the distribution-of-the-product approach, which rarely disagree. 
		The percentile bootstrap confidence interval is a good compromise test.
	},
}

@InBook{
	Lib-Mediation-Bootstrap-Koopman-2014
	,
	author     = {
		Koopman, Joel 
		and 
		Howe, Michael 
		and 
		Hollenbeck, John R.
	},
	booktitle  = {
		More statistical and methodological myths and urban legends: Doctrine, verity and fable in organizational and social sciences
	},
	date       = {
		2014
	},
	title      = {
		Pulling the {Sobel} test up by its bootstraps
	},
	bookauthor = {
		Lance, Charles E. 
		and 
		Vandenberg, Robert J.
	},
	isbn       = {
		9780203775851
	},
	pages      = {
		224--243
	},
	publisher  = {
		Routledge/Taylor \& Francis Group
	},
	location = {},
	doi = {
		10.4324/9780203775851 
	},
	isbn = {
		9780203775851
	},
	file = {
		references/9780203775851_11.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract   = {
		In the domain of building and testing theory, mediation relationships are among the most important that can be proposed. 
		Mediation helps to explicate our theoretical models (Leavitt, Mitchell, \& Peterson, 2010) and addresses the fundamental question of why two constructs are related (Whetten, 1989). 
		One of the better-known methods for testing mediation is commonly referred to as the ``Sobel test,'' named for the researcher who derived a standard error (Sobel, 1982) to test the significance of the indirect effect. 
		Recently, a number of different research teams (e.g., Preacher \& Hayes, 2004; Shrout \& Bolger, 2002) have criticized the Sobel test because this standard error requires an assumption of normality for the indirect effect sampling distribution. This distribution tends to be positively skewed (i.e,. not normal), 
		particularly in small samples, 
		and so this assumption can be problematic (Preacher \& Hayes, 2004; Stone \& Sobel, 1990).
		As a result, the statistical power of the Sobel test may be lessened in these contexts (Preacher \& Hayes 2004; Shrout \& Bolger, 2002). 
		In light of this concern, 
		some scholars have advocated instead for the use of bootstrapping to test the significance of the indirect effect (e.g.. Shrout \& Bolger 2002). 
		Bootstrapping requires no a priori assumption about the shape of the sampling distribution because this distribution is empirically estimated using a resampling procedure (Efron \& Tibshirani, 1993). 
		As a result, 
		departures from normality are less troublesome when creating a confidence interval for the indirect effect. 
		For this reason, 
		bootstrapping is now widely believed to be inherently superior to the Sobel test when testing the significance of the indirect effect in organizational research. 
		Our position is that this belief constitutes an urban legend. As with all statistical urban legends, there is an underlying kernel of truth to the belief that bootstrapping is superior to the Sobel test. 
		However, 
		as we discuss in this chapter, 
		there are several reasons to be concerned with a broad belief in the superiority of bootstrapping. 
		We begin with a brief overview of mediation testing focusing on the Sobel test and bootstrapping and then explain the underlying kernel of truth that has propelled bootstrapping to the forefront of mediation testing in organizational research. 
		Subsequently, 
		we discuss four areas of concern that cast doubt on the belief of the inherent superiority of bootstrapping. 
		Finally, 
		we conclude with recommendations concerning the future of mediation testing in organizational research.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Koopman-2015
	,
	author       = {
		Koopman, Joel 
		and 
		Howe, Michael 
		and 
		Hollenbeck, John R. 
		and 
		Sin, 
		Hock-Peng
	},
	date         = {
		2015
	},
	journaltitle = {
		Journal of Applied Psychology
	},
	title        = {
		Small sample mediation testing: Misplaced confidence in bootstrapped confidence intervals
	},
	doi          = {
		10.1037/a0036635
	},
	number       = {
		1
	},
	pages        = {
		194--202
	},
	volume       = {
		100
	},
	publisher    = {
		American Psychological Association ({APA})
	},
	file = {
		references/10.1037%2Fa0036635.pdf
	},
	library = {},
	keywords = {
		mediation, 
		bootstrapping, 
		permutation, 
		Bayes
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Bootstrapping is an analytical tool commonly used in psychology to test the statistical significance of the indirect effect in mediation models. 
		Bootstrapping proponents have particularly advocated for its use for samples of 20-80 cases. 
		This advocacy has been heeded, 
		especially in the Journal of Applied Psychology, 
		as researchers are increasingly utilizing bootstrapping to test mediation with samples in this range. 
		We discuss reasons to be concerned with this escalation, 
		and in a simulation study focused specifically on this range of sample sizes, 
		we demonstrate not only that bootstrapping has insufficient statistical power to provide a rigorous hypothesis test in most conditions but also that bootstrapping has a tendency to exhibit an inflated Type I error rate.
		We then extend our simulations to investigate an alternative empirical resampling method as well as a Bayesian approach and demonstrate that they exhibit comparable statistical power to bootstrapping in small samples without the associated inflated Type I error. 
		Implications for researchers testing mediation hypotheses in small samples are presented. 
		For researchers wishing to use these methods in their own research, 
		we have provided R syntax in the online supplemental materials.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Tofighi-2020
	,
	author       = {
		Tofighi, Davood
		and
		Kelley, Ken
	},
	date         = {
		2020
	},
	journaltitle = {
		Psychological Methods
	},
	title        = {
		Improved inference in mediation analysis: Introducing the model-based constrained optimization procedure
	},
	doi          = {
		10.1037/met0000259
	},
	pages        = {
		496--515
	},
	volume       = {
		25
	},
	publisher    = {
		{American Psychological Association ({APA})}
	},
	file = {
		references/10.1037%2Fmet0000259.pdf
	},
	library = {},
	keywords = {},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Mediation analysis is an important approach for investigating causal pathways.
		One approach used in mediation analysis is the test of an indirect effect,
		which seeks to measure how the effect of an independent variable impacts an outcome variable through one or more mediators.
		However, in many situations the proposed tests of indirect effects, including popular confidence interval-based methods,
		tend to produce poor Type I error rates when mediation does not occur and,
		more generally, only allow dichotomous decisions of ``not significant'' or ``significant'' with regards to the statistical conclusion.
		To remedy these issues, we propose a new method, a likelihood ratio test (LRT),
		that uses non-linear constraints in what we term the model-based constrained optimization (MBCO) procedure.
		The MBCO procedure (a) offers a more robust Type I error rate than existing methods;
		(b) provides a p-value, which serves as a continuous measure of compatibility of data with the hypothesized null model
		(not just a dichotomous reject or fail-to-reject decision rule);
		(c) allows simple and complex hypotheses about mediation
		(i.e., one or more mediators; different mediational pathways),
		and (d) allows the mediation model to use observed or latent variables.
		The MBCO procedure is based on a structural equation modeling framework
		(even if latent variables are not specified)
		with specialized fitting routines,
		namely with the use of non-linear constraints.
		We advocate using the MBCO procedure to test hypotheses about an indirect effect
		in addition to reporting a confidence interval to capture uncertainty about the indirect effect
		because this combination transcends existing methods.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Pesigan-2020
	,
	author       = {
		Pesigan, Ivan Jacob Agaloos
		and
		Cheung, Shu Fai
	},
	date         = {
		2020-12
	},
	journaltitle = {
		Frontiers in Psychology
	},
	title        = {
		{SEM}-based methods to form confidence intervals for indirect effect: Still applicable given nonnormality, under certain conditions
	},
	doi          = {
		10.3389/fpsyg.2020.571928
	},
	volume       = {
		11
	},
	publisher    = {
		Frontiers Media {SA}
	},  
	file = {
		references/10.3389%2Ffpsyg.2020.571928.pdf
	},
	library = {},
	keywords = {
		mediation, 
		nonnormal, 
		confidence interval, 
		structural equation modeling,
		bootstrapping
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		A SEM-based approach using likelihood-based confidence interval (LBCI) has been proposed to form confidence intervals for unstandardized and standardized indirect effect in mediation models.
		However,
		when used with the maximum likelihood estimation,
		this approach requires that the variables are multivariate normally distributed.
		This can affect the LBCIs of unstandardized and standardized effect differently.
		In the present study,
		the robustness of this approach when the predictor is not normally distributed but the error terms are conditionally normal,
		which does not violate the distributional assumption of ordinary least squares (OLS) estimation,
		is compared to four other approaches:
		nonparametric bootstrapping,
		two variants of LBCI,
		LBCI assuming the predictor is fixed (LBCI-Fixed-X) and LBCI based on ADF estimation (LBCI-ADF),
		and Monte Carlo.
		A simulation study was conducted using a simple mediation model and a serial mediation model,
		manipulating the distribution of the predictor.
		The Monte Carlo method performed worst among the methods.
		LBCI and LBCI-Fixed-X had suboptimal performance when the distributions had high kurtosis and the population indirect effects were medium to large.
		In some conditions,
		the problem was severe even when the sample size was large.
		LBCI-ADF and nonparametric bootstrapping had coverage probabilities close to the nominal value in nearly all conditions,
		although the coverage probabilities were still suboptimal for the serial mediation model when the sample size was small with respect to the model.
		Implications of these findings in the context of this special case of nonnormal data were discussed.
	},
}

@Article{
	Lib-Mediation-Bootstrap-Cheung-2022
	,
	author       = {
		Cheung, Shu Fai 
		and 
		Pesigan, Ivan Jacob Agaloos 
		and 
		Vong, Weng Ngai
	},
	date         = {
		2022-03
	},
	journaltitle = {
		Behavior Research Methods
	},
	title        = {
		{DIY} bootstrapping: Getting the nonparametric bootstrap confidence interval in {SPSS} for any statistics or function of statistics (when this bootstrapping is appropriate)
	},
	doi          = {
		10.3758/s13428-022-01808-5
	},
	publisher    = {
		Springer Science and Business Media {LLC}
	},
	file = {
		references/10.3758%2Fs13428-022-01808-5.pdf
	},
	library = {},
	keywords = {
		bootstrapping,
		effect sizes,
		confidence intervals
	},
	addendum = {},
	note = {},
	annotation = {
		Lib-Mediation-Bootstrap
	},
	abstract     = {
		Researchers can generate bootstrap confidence intervals for some statistics in SPSS using the BOOTSTRAP command. 
		However, 
		this command can only be applied to selected procedures, 
		and only to selected statistics in these procedures. 
		We developed an extension command and prepared some sample syntax files based on existing approaches from the Internet to illustrate how researchers can 
		(a) generate a large number of nonparametric bootstrap samples, 
		(b) do desired analysis on all these samples, and 
		(c) form the bootstrap confidence intervals for selected statistics using the OMS commands. 
		We developed these tools to help researchers apply nonparametric bootstrapping to any statistics for which this method is appropriate, including statistics derived from other statistics, 
		such as standardized effect size measures computed from the t test results. 
		We also discussed how researchers can extend the tools for other statistics and scenarios they encounter.
	},
}

@Comment{jabref-meta: databaseType:biblatex;}